{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b9227f7",
   "metadata": {},
   "source": [
    "# Mise à disposition du jeu de données stroke_dataset via une API REST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02037c20",
   "metadata": {},
   "source": [
    "## Description du dataset\n",
    "\n",
    "Le jeu de données utilisé provient de Kaggle : [Stroke Prediction Dataset](https://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset).  \n",
    "Il contient des données de patients avec différentes caractéristiques médicales et sociales, ainsi que l'information si le patient a subi un accident vasculaire cérébral (AVC) ou non.\n",
    "\n",
    "Télécharger les données et ajouter les dans un dossier data/.\n",
    "\n",
    "Les colonnes des données sont :  \n",
    "- `id` : Identifiant unique du patient  \n",
    "- `gender` : Sexe  \n",
    "- `age` : Âge  \n",
    "- `hypertension` : Présence d'hypertension (0 ou 1)  \n",
    "- `heart_disease` : Présence de maladie cardiaque (0 ou 1)  \n",
    "- `ever_married` : Statut marital  \n",
    "- `work_type` : Type d'emploi  \n",
    "- `Residence_type` : Urbaine ou rurale  \n",
    "- `avg_glucose_level` : Moyenne du taux de glucose  \n",
    "- `bmi` : Indice de masse corporelle  \n",
    "- `smoking_status` : Statut tabagique  \n",
    "- `stroke` : Présence d'AVC (0 ou 1)\n",
    "\n",
    "## Projet\n",
    "\n",
    "Vous devez exposer les données patients du jeu de données via une API REST afin que les données soit utilisables par d'autres équipes (médecins, data science, étude, etc.).\n",
    "\n",
    "Cette API REST sera développée avec FastAPI et les spécifications sont les suivantes :\n",
    "| Méthode | Endpoint                                      | Fonctionnalité                                                                                                    |\n",
    "| ------- | --------------------------------------------- | ----------------------------------------------------------------------------------------------------------------- |\n",
    "| `GET`   | `/patients/{id}`                              | Récupère les détails d’un patient donné (via son identifiant unique)                                              |\n",
    "| `GET`   | `/patients?stroke=1&gender=Female&max_age=60` | Renvoie les patients filtrés selon plusieurs critères : AVC (oui/non), genre, âge maximal                         |\n",
    "| `GET`   | `/stats/`                                     | Fournit des statistiques agrégées sur les patients (ex. : nb total de patients, âge moyen, taux d’AVC, répartition hommes/femmes, etc.) |\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Quelques définitions\n",
    "\n",
    "\n",
    "1. Qu’est-ce qu’une API REST ?\n",
    "\n",
    "- API signifie Application Programming Interface (Interface de Programmation d’Application). C’est un ensemble de règles et de protocoles qui permettent à des logiciels de communiquer entre eux.\n",
    "- REST signifie Representational State Transfer. C’est un style architectural pour concevoir des services web.\n",
    "Il en existe d'autres mais REST est celui que vous rencontrerez le plus souvent.\n",
    "- Vous avez utilisé une API REST via l'API Google Books.\n",
    "\n",
    "- A quoi sert une API REST ?\n",
    "\n",
    "    - Permet à différentes applications de communiquer facilement, même si elles sont écrites dans des langages différents.\n",
    "    - Permet d’accéder à des services distants (ex : bases de données, services web) de manière standardisée.\n",
    "    - Facilite la création d’applications modulaires et évolutives (front-end, back-end, mobile, etc.)\n",
    "\n",
    "2. Principes clés d’une API REST\n",
    "\n",
    "- a. Utilisation du protocole HTTP\n",
    "Les échanges entre client et serveur utilisent des méthodes HTTP standard comme :\n",
    "\n",
    "    - GET : pour récupérer des données\n",
    "    - POST : pour envoyer ou créer des données\n",
    "    - PUT : pour mettre à jour des données\n",
    "    - DELETE : pour supprimer des données\n",
    "\n",
    "- b. Accès aux ressources via des URLs\n",
    "\n",
    "Chaque ressource (par exemple un livre, un utilisateur) est accessible via une URL unique.\n",
    "\n",
    "Exemple fictif:\n",
    "    https://api.example.com/books/123 pour accéder au livre d’identifiant 123.\n",
    "\n",
    "- c. Stateless (sans état)\n",
    "\n",
    "Le serveur ne conserve aucune information sur le client entre deux requêtes. Chaque requête doit contenir toutes les informations nécessaires.\n",
    "\n",
    "- d. Représentations des données\n",
    "\n",
    "Les données sont envoyées et reçues généralement en format JSON ou XML, qui sont faciles à lire et à manipuler.\n",
    "\n",
    "- e. Utilisation de codes status HTTP\n",
    "\n",
    "Chaque réponse du serveur est accompagnée d’un code HTTP indiquant le résultat de la requête. (cf [liste des codes](https://developer.mozilla.org/en-US/docs/Web/HTTP/Reference/Status))\n",
    "\n",
    "## Outils utilisés\n",
    "1. FastAPI\n",
    "\n",
    "FastAPI est un framework Python moderne, rapide et très utilisé dans le milieu professionnel pour construire des API REST. \n",
    "\n",
    "Il permet :\n",
    "- une définition simple des routes et des paramètres  \n",
    "- La génération automatique de documentation interactive (Swagger UI)  \n",
    "- FastAPI lit les requêtes entrantes, les traite avec ton code Python, et retourne une réponse HTTP (en JSON).\n",
    "\n",
    "2. Uvicorn : exécute l'application FastAPI\n",
    "\n",
    "- Uvicorn est un serveur ASGI (Asynchronous Server Gateway Interface) : c'est une interface standard pour gérer les requêtes de manière asynchrone et performante, notamment utile pour les applications modernes.\n",
    "- Il attend les requêtes HTTP (par exemple depuis un navigateur), les transmet à FastAPI, et renvoie la réponse.\n",
    "- Uvicorn permet à l'API de fonctionner : sans Uvicorn ou un autre serveur, FastAPI ne peut pas fonctionner.\n",
    "\n",
    "\n",
    "3. Swagger UI : l’interface de doc et test interactive\n",
    "\n",
    "- Swagger UI est généré automatiquement par FastAPI.\n",
    "- C’est une interface web qui permet de :\n",
    "    - Voir toutes les routes disponibles dans l'API\n",
    "    - Tester les routes en envoyant des requêtes sans écrire de code (bouton try it out)\n",
    "    - Voir les paramètres attendus et les formats de réponse\n",
    "    \n",
    "4. Résumé des interactions\n",
    "\n",
    "- Tester la route de base de l'API grâce à la commande :\n",
    "```bash\n",
    "    poetry run fastapi dev stroke_api/main.py\n",
    "```\n",
    "\n",
    "--> Qu'est-ce qu'il se passe derrière cette commande ?\n",
    "\n",
    "- Uvicorn démarre un serveur local\n",
    "- FastAPI génère automatiquement une interface : Swagger UI, accessible sur http://127.0.0.1:8000/docs qui affiche toutes les routes définies dans le code python FastAPI\n",
    "- Quand on clique sur \"Try it out\" dans Swagger UI, Swagger envoie une requête HTTP au serveur (ici Uvicorn)\n",
    "- Le serveur (Uvicorn) la reçoit, l’envoie à FastAPI, qui traite et renvoie une réponse\n",
    "- Swagger UI affiche la réponse de l’API (par ex : liste de patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02e38a2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Import des bibliothèques utiles au projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548f6eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cf9064",
   "metadata": {},
   "source": [
    "## 1. Prétraitement des données / Data preprocessing\n",
    "\n",
    "Les données réelles sont rarement prêtes à être utilisées directement. Elles peuvent contenir des erreurs, des valeurs manquantes, des doublons, des formats incohérents, ou ne pas être adaptées au modèle ou au système cible.\n",
    "\n",
    "Le prétraitement consiste à nettoyer, structurer et transformer les données brutes avant de les exploiter dans un projet (modèle IA, API, visualisation, etc.).\n",
    "\n",
    "Vous avez déjà prétraité des données, petit rappel des éléments sur lesquels travailler dans un prétraitment classique et les méthodes pandas qu'il est possible d'utiliser pour les différentes étapes (des exeples d'utilisation des méthodes pandas sont disponibles dans la doc) : \n",
    "- explorer les données pour identifier les types de données, valeurs manquantes, incohérence ([info](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.info.html), [dtypes](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dtypes.html))\n",
    "- adapter les types si nécessaire ([astypes](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.astype.html))\n",
    "- identifier les doublons et les supprimer s'il y en a ([duplicated](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html), [drop_duplicates](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html))\n",
    "- traiter les valeurs manquantes s'il y en a ([fillna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html), [dropna](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html), [replace](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html))\n",
    "- identifier les incohérences éventuelles (valeurs aberrantes/outliers) en vérifiant si les valeurs min, max, moyennes sont raisonnables (recherche internet si nécessaire) ([describe](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html)), et les traiter.\n",
    "- Traiter les valeurs aberrantes si vous en détectez ([loc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html) pour récupérer les lignes qui répondent à une certaine condition, cf exemple ci-dessous)\n",
    "\n",
    "\n",
    "**Exemple df.loc :**\n",
    "\n",
    "Récupérer toutes les lignes de df telles que la valeur de \"nom de colonne\" >= 0\n",
    "\n",
    "```df_subset = df.loc[stroke_data_df['nom de colonne'] >= 0]```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb65710",
   "metadata": {},
   "source": [
    "---\n",
    "### **TODO**\n",
    "1.a. Prétraiter les données du dataset.\n",
    "\n",
    "\n",
    "1.b. Documenter dans le README.md :\n",
    "- Les étapes de prétraitement,\n",
    "- Justification des choix concernant le traitement des valeurs manquantes (si besoin),\n",
    "- Liste des valeurs raisonnables utilisées pour détecter les valeurs aberrantes, \n",
    "- Justification des choix pour traiter les valeurs aberrantes (si besoin).\n",
    "\n",
    "2.a. Chercher des infos sur le format de fichier parquet et indiquer les sources consultées : \n",
    "- Différence principale avec le format csv ? </br>\n",
    "Le format parquet transforme les données en binaire, compresse les données (donc moins volumineux), optimal pour traiter un grand nombre de données.\n",
    "- Dans quels cas l'utiliser ? </br>\n",
    "Principalement pour le stockage de données tabulaires.\n",
    "- Pourquoi c'est un format adapté aux gros volumes de données ? </br>\n",
    "Parce qu'il compresse les données.\n",
    "\n",
    "\n",
    "\n",
    "2.b. Sauvegarder les données prétraiteées dans un fichier parquet ([to_parquet](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_parquet.html)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f760f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement de données\n",
    "df = pd.read_csv(\"data/healthcare-dataset-stroke-data.csv\")\n",
    "# df.head()\n",
    "# df.isnull().sum()\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf579c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolement des données manquantes\n",
    "\n",
    "df_null = df.loc[df['bmi'].isna()]\n",
    "# df_null.describe()\n",
    "df_null_male = df_null.loc[df_null['gender'] == 'Male']\n",
    "print(df_null_male)\n",
    "\n",
    "# Imputation des données manquantes par rapport à l'âge, au sexe, au statut SP et taux de glucose\n",
    "# Etablissement d'une médiane selon ces variables\n",
    "df_bmi_impute = df.groupby(['gender', 'work_type', 'age', 'avg_glucose_level'])['bmi'].mean()\n",
    "\n",
    "print(df_bmi_impute)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208e91f9",
   "metadata": {},
   "source": [
    "Données d'âge trop éparses. </br>\n",
    "- Création d'une fonction qui segmente les âges en catégories\n",
    "- Création d'une colonne 'age_category'\n",
    "- Attribution de la catégorie d'âge pour chaque patient\n",
    "- Calcul de la médiane de chaque category\n",
    "- Utilisation des résultats pour trouver un imc aux patients n'ayant pas renseignés cette donnée"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd24e94f",
   "metadata": {},
   "source": [
    "Données sur le taux de glycémie moyen </br>\n",
    "- Même procédure qu'avec l'âge: créer trois catégories\n",
    "- Taux de glucose faible / normal / élevé\n",
    "- Faible < 90 / Normal <= 125 / Elevé > 126"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594c723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copie du df\n",
    "\n",
    "df_copy = df.to_csv('stroke_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32206954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export de la copie csv en dataframe\n",
    "df_stroke_cleaned = pd.read_csv('stroke_clean.csv')\n",
    "\n",
    "df_stroke_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d406e637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour l'imputation de la catégorie d'âge\n",
    "def impute_age_category(age):\n",
    "    if age < 13:\n",
    "        return 'enfant'\n",
    "    elif age < 18:\n",
    "        return 'ado'\n",
    "    elif age <= 45:\n",
    "        return 'adulte_21_45'\n",
    "    elif age <= 65:\n",
    "        return 'adulte_46_65'\n",
    "    else:\n",
    "        return 'senior'\n",
    "\n",
    "# Création colonne & imputation des patients selon leur âge dans une catégorie d'âge\n",
    "df_stroke_cleaned['age_category'] = df_stroke_cleaned['age'].apply(impute_age_category)\n",
    "\n",
    "# AJOUT : imputation du statut fumeur pour les enfants\n",
    "df_stroke_cleaned.loc[df_stroke_cleaned['age_category'] == 'enfant', 'smoking_status'] = 'never smoked'\n",
    "\n",
    "# Calcul de la médiane de l'IMC selon la catégorie d'âge\n",
    "bmi_medians = df_stroke_cleaned.groupby('age_category')['bmi'].median()\n",
    "\n",
    "# Fonction pour catégoriser le taux de glycémie\n",
    "def impute_glucose_category(glucose):\n",
    "    if glucose < 90:\n",
    "        return 'faible'\n",
    "    elif glucose <= 125:\n",
    "        return 'normal'\n",
    "    else:\n",
    "        return 'élevé'\n",
    "\n",
    "# Création colonne & imputation dans les catégories (glycémie)\n",
    "df_stroke_cleaned['glucose_category'] = df_stroke_cleaned['avg_glucose_level'].apply(impute_glucose_category)\n",
    "\n",
    "# Calcul de la médiane du BMI selon le genre, statut SP, catégorie d'âge et taux de glycémie\n",
    "bmi_medians_multi = (\n",
    "    df_stroke_cleaned.groupby(['gender', 'work_type', 'age_category', 'glucose_category'])['bmi']\n",
    "    .median()\n",
    "    .round(1)\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "# Fusion avec le dataset nettoyé\n",
    "df_stroke_cleaned = df_stroke_cleaned.merge(\n",
    "    bmi_medians_multi,\n",
    "    on=['gender', 'work_type', 'age_category', 'glucose_category'],\n",
    "    how='left',\n",
    "    suffixes=('', '_impute')\n",
    ")\n",
    "\n",
    "# Remplacement des valeurs manquantes\n",
    "df_stroke_cleaned['bmi'] = df_stroke_cleaned['bmi'].fillna(df_stroke_cleaned['bmi_impute'])\n",
    "df_stroke_cleaned.drop(columns=['bmi_impute'], inplace=True)\n",
    "df_stroke_cleaned.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "# Export et vérification\n",
    "print('Valeur manquantes restantes: ', df_stroke_cleaned['bmi'].isna().sum())\n",
    "df = df_stroke_cleaned.to_csv('df_final_test.csv')\n",
    "df = pd.read_csv('df_final_test.csv')\n",
    "df = df.to_parquet('df_final_test', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dfaae1",
   "metadata": {},
   "source": [
    "-----\n",
    "## Développement de l'API\n",
    "\n",
    "A présent que les données sont propres, on peut débuter la création de l'API.\n",
    "\n",
    "Pour cela, vous allez avoir besoin de quelques fonctions permettant de filtrer les données.\n",
    "\n",
    "Vous allez les définir ci-dessous, ce qui vous permettra de les tester puis les fonctions seront reportées dans le fichier filters.py."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c2b0d0",
   "metadata": {},
   "source": [
    "## Route `/patients/`\n",
    "- Cette route retourne une liste filtrée de patients\n",
    "- On souhaite pouvoir filtrer par `gender`, `stroke` ou `max_age`\n",
    "\n",
    "L'objectif est ici de définir une fonction python qui prend en entrée les paramètres optionnels : _gender_, *stroke*, *max_age* et qui renvoie un dictionnaire filtré des données.\n",
    "\n",
    "On décompose la rédaction de cette fonction en plusieurs étapes. \n",
    "\n",
    "Dans un premier temps, écrire et tester les filtres que l'on souhaite appliquer sur les données (utiliser [loc](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a060c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_final_test.csv')\n",
    "df =df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b25d9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer le dataframe pour ne garder que les patients pour lesquels \"stroke=1\"\n",
    "stroke = df.loc[df['stroke'] == 1]\n",
    "print(stroke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eca4b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les données pour ne garder que les patients pour lesquels \"gender=\"male\"\n",
    "gender = df.loc[df['gender'] == 'Male']\n",
    "print(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bac1cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrer les données pour ne garder que les patients tels que \"age <= max_age\"\n",
    "max_age = df['age'].max()\n",
    "print(max_age)\n",
    "df_max_age_patient = df.loc[df['age'] <= max_age]\n",
    "\n",
    "print(df_max_age_patient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9f1928",
   "metadata": {},
   "source": [
    "Appliquer successivement les 3 filtres au sein d'une fonction qui prend en entrée le dataframe, _stroke_, _gender_, _max_age_ et qui renvoie une liste de dictionnaire de patients (utiliser la méthode pandas [to_dict](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_dict.html)).\n",
    "\n",
    "Exemple\n",
    "```\n",
    "[{'id': 9046,\n",
    "  'gender': 'Male',\n",
    "  'age': 67.0,\n",
    "  ...\n",
    "  'smoking_status': 'formerly smoked',\n",
    "  'stroke': 1},\n",
    " {'id': 31112,\n",
    "  'gender': 'Male',\n",
    "  'age': 80.0,\n",
    "  ...\n",
    "  'smoking_status': 'formerly smoked',\n",
    "  'stroke': 1}]\n",
    "  ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c364a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_patients(df: pd.DataFrame, gender: str, max_age: float, stroke: int) -> list[dict]:\n",
    "    \n",
    "    filtered_df = df[\n",
    "        (df['stroke'] == stroke) &\n",
    "        (df['gender'] == gender) &\n",
    "        (df['age'] <= max_age)\n",
    "    ]\n",
    "\n",
    "    return filtered_df.to_dict(orient='records')\n",
    "\n",
    "filtre1 = filter_patients(df, max_age= 80,gender= 'Male', stroke=1)\n",
    "print(filtre1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85017c8f",
   "metadata": {},
   "source": [
    "A présent on souhaite ajouter des informations sur les types des paramètres et valeurs de retour de la fonction pour faciliter sa compréhension et son utilisation, ce qu’on appelle l’annotation de type (type hinting).\n",
    "\n",
    "Cette pratique facilite la lecture et la maintenance du code.\n",
    "\n",
    "Quels changements pour la fonction ?\n",
    "\n",
    "A la suite de chaque paramètre, on ajoute le type attendu pour le paramètre. À la suite des paramètres on ajoute le type de ce que qui est retourné par la fonction, dans l'exemple ici : \n",
    "\n",
    "```def filter_patient(stroke_data_df: pd.DataFrame, gender: str, etc) -> list[dict]```\n",
    "\n",
    "Ajouter les types dans la définition de la fonction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b7f0a",
   "metadata": {},
   "source": [
    "Tester la fonction en ne mettant pas de valeur pour *max_age*.\n",
    "\n",
    "Que se passe-t-il ? </br>\n",
    "Ca ne fonctionne plus, voici l'erreur : TypeError: filter_patients() got multiple values for argument 'gender'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78da71a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_patients(df: pd.DataFrame, gender: str, max_age: float, stroke: int) -> list[dict]:\n",
    "    \n",
    "    filtered_df = df[\n",
    "        (df['stroke'] == stroke) &\n",
    "        (df['gender'] == gender) &\n",
    "        (df['age'] <= max_age)\n",
    "    ]\n",
    "\n",
    "    return filtered_df.to_dict(orient='records')\n",
    "\n",
    "filtre1 = filter_patients(df, max_age , gender= 'Male' , stroke=1)\n",
    "print(filtre1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956bca5f",
   "metadata": {},
   "source": [
    "Dans la fonction écrite ci-dessus, chaque paramètre est obligatoire. \n",
    "\n",
    "On souhaite pouvoir filtrer les patients sur 0, 1 ou 2 des paramètres de la fonction (filtrer seulement sur *max_age*  mais ne pas appliquer de filtres sur _gender_ et _stroke_ par exemple).\n",
    "\n",
    "On peut rendre optionnel les paramètres d'un fonction en choisissant une valeur par défault. Si on utilise la fonction en n'utilisant pas ces paramètres alors la valeur par défault est utilisé.\n",
    "\n",
    "Copier coller votre fonction ci-dessous et ajouter en paramètre : `max_age=None`\n",
    "\n",
    "et ajouter la condition suivante **avant le filtre** sur `max_age` : \n",
    "\n",
    "```if max_age is not None : ``` \n",
    "\n",
    "Si la fonction _filter_patient_ est appelée sans argument *max_age*, alors le filtre sur *max_age* n'est pas appliqué. \n",
    "\n",
    "Il est tout à fait possible de définir une valeur par défault par exemple 30 ans : dans ce cas si la fonction est appelée sans argument *max_age*, alors par défault on filtre les patients ayant moins de 30 ans.\n",
    "\n",
    "**ATTENTION :** Les paramètres optionnels doivent toujours être à la fin de la liste de paramètres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f987b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fonction avec max_age optionnel\n",
    "def filter_patients(df: pd.DataFrame, gender: str, stroke: int, max_age: float = None) -> list[dict]:\n",
    "    filtered_df = df[\n",
    "        (df['stroke'] == stroke) &\n",
    "        (df['gender'] == gender)\n",
    "    ]\n",
    "\n",
    "    if max_age is not None:\n",
    "        filtered_df = filtered_df[filtered_df['age'] <= max_age]\n",
    "\n",
    "    return filtered_df.to_dict(orient='records')\n",
    "\n",
    "# Appel de la fonction\n",
    "patients = filter_patients(df, gender='Male', stroke=1, max_age=30)\n",
    "print(patients)\n",
    "# # Affichage de chaque entrée\n",
    "# print(\"Patients filtrés :\")\n",
    "# for patient in patients:\n",
    "#     print(patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23084a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test fonction sans argument max_age\n",
    "# Fonction avec max_age optionnel\n",
    "def filter_patients(df: pd.DataFrame, gender: str, stroke: int, max_age: float = None) -> list[dict]:\n",
    "    filtered_df = df[\n",
    "        (df['stroke'] == stroke) &\n",
    "        (df['gender'] == gender)\n",
    "    ]\n",
    "\n",
    "    if max_age is not None:\n",
    "        filtered_df = filtered_df[filtered_df['age'] <= max_age]\n",
    "\n",
    "    return filtered_df.to_dict(orient='records')\n",
    "\n",
    "# Appel de la fonction\n",
    "patients = filter_patients(df, gender='Male', stroke=1)\n",
    "print(patients)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe7f5de",
   "metadata": {},
   "source": [
    "Ajouter des valeurs par défault et les conditions pour chaque filtre.\n",
    "\n",
    "Pour les types, on indique qu'il s'agit de paramètres optionels en utilisant le module python _typing_\n",
    "\n",
    "```\n",
    "from typing import Optional\n",
    "def filter_patient(stroke_data_df: pd.DataFrame, gender: Optional[str] = None,etc)\n",
    "```\n",
    "\n",
    "Adapter les types en utilisant ce modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55db8ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction avec ajout de paramètres par défault et de type\n",
    "from typing import Optional\n",
    "def filter_patient(stroke_data_df: pd.DataFrame, stroke: Optional[int] = None, gender: Optional[str] = None, max_age: Optional[int] = None):\n",
    "    filtered_df = stroke_data_df.copy()\n",
    "    if max_age is not None:\n",
    "        filtered_df = filtered_df[filtered_df['age'] <= max_age]\n",
    "    if stroke is not None:\n",
    "        filtered_df = filtered_df[filtered_df['stroke'] == stroke]\n",
    "    if gender is not None:\n",
    "        filtered_df = filtered_df[filtered_df['gender'] == gender]\n",
    "    return filtered_df.to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c073eb",
   "metadata": {},
   "source": [
    "Tester la fonction sans argument pour les filtres, elle doit donc renvoyer le dataframe non filtré."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ffbfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test fonction sans argument pour les filtres\n",
    "\n",
    "from typing import Optional\n",
    "def filter_patient(stroke_data_df: pd.DataFrame, stroke: Optional[int] = None, gender: Optional[str] = None, max_age: Optional[int] = None):\n",
    "    filtered_df = stroke_data_df.copy()\n",
    "    if max_age is not None:\n",
    "        filtered_df = filtered_df[filtered_df['age'] <= max_age]\n",
    "    if stroke is not None:\n",
    "        filtered_df = filtered_df[filtered_df['stroke'] == stroke]\n",
    "    if gender is not None:\n",
    "        filtered_df = filtered_df[filtered_df['gender'] == gender]\n",
    "    return filtered_df.to_dict(orient='records')\n",
    "\n",
    "patient = filter_patient(df)\n",
    "print(patient)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7816b86",
   "metadata": {},
   "source": [
    "Cette fonction va être utilisée dans la définition de l'API pour créer une route qui permette d'accéder à des données filtrées sur les patients.\n",
    "\n",
    "Dans le fichier de définition de l'API, toutes les fonctions vont travailler sur les données du fichier. \n",
    "\n",
    "Pour alléger les fonctions on va donc utiliser une **variable globale** pour les données et supprimer le paramètre `df` de la fonction.\n",
    "\n",
    "On lit les données en début de fichier puis on travaille au sein des fonctions sur une copie du dataframe de données.\n",
    "\n",
    "\n",
    "**En résumé les modifications à faire sont :**\n",
    "\n",
    "\n",
    "- Supprimer le paramètre df de la fonction,\n",
    "- Ajouter en début de fonction :  \n",
    "```df = stroke_data_df.copy()```\n",
    "\n",
    "1. Dans le fichier filters.py, il suffit d'ajouter : \n",
    "- lecture du fichier de données prétraitée dans la variable *df* en début de fichier (utiliser pandas),\n",
    "- @app.get(\"/patients/\") pour définir le route,\n",
    "puis la fonction.\n",
    "\n",
    "2. Dans le fichier api.py: appeler la fonction dans la route correspondante.\n",
    "\n",
    "Tester la route avec \n",
    "\n",
    "```poetry run fastapi dev stroke_api/main.py```\n",
    "\n",
    "http://127.0.0.1:8000/docs : utiliser la fonctionnalité Try it out pour tester la route."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b80fee",
   "metadata": {},
   "source": [
    "---\n",
    "## Autres routes\n",
    "\n",
    "De la même manière, créer les fonctions appropriées pour la création de :\n",
    "- la route `/patients/{id}` : Récupère les détails d’un patient donné (via son identifiant unique) \n",
    "\n",
    "- la route `/stats/` : Fournit des statistiques agrégées sur les patients (ex. : nb total de patients, âge moyen, taux d’AVC, répartition hommes/femmes).\n",
    "\n",
    "- Lister les tâches à faire sous forme d'issue github : travailler sur une branche différentes pour l'ajout de chacune des routes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry init-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
